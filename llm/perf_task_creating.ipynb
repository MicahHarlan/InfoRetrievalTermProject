{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T04:01:21.182419Z",
     "start_time": "2024-04-18T04:01:20.800774Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:01:21.253461Z",
     "start_time": "2024-04-18T04:01:21.183394Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('./movie_tags_in_database.csv')",
   "id": "1346b8d4f9ef0fe0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:01:21.255584Z",
     "start_time": "2024-04-18T04:01:21.254177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import openai\n",
    "# client = openai.Client(api_key=\"sk-proj-LjelMrYHxCiy2InWAc2QT3BlbkFJRsSNDNahsnVJEN5r0J0B\")"
   ],
   "id": "d04b208c19e044f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prompt generating using Prediction Guard",
   "id": "fd516ca35d7b13b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:02:29.638889Z",
     "start_time": "2024-04-18T04:02:29.388840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import predictionguard as pg\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n"
   ],
   "id": "5826e9d2cdb82cc6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:02:32.848378Z",
     "start_time": "2024-04-18T04:02:32.843831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_token():\n",
    "  with open(\"../../config/predictionguard.json\", 'r') as file:\n",
    "    config = json.load(file)\n",
    "    return config['api_key']"
   ],
   "id": "3b2d721acaf89988",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:05:56.580684Z",
     "start_time": "2024-04-18T04:05:56.522800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Prompt(BaseModel):\n",
    "    prompt: str = Field(\n",
    "        ...,\n",
    "        title=\"Prompt\",\n",
    "        description=\"The prompt to be used for generating the completion.\",\n",
    "    )   "
   ],
   "id": "95dcec69fffdee92",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:15:41.519350Z",
     "start_time": "2024-04-18T14:15:41.510342Z"
    }
   },
   "cell_type": "code",
   "source": "parser = PydanticOutputParser(pydantic_object=Prompt)",
   "id": "b8e34075c522f4e4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:15:56.050652Z",
     "start_time": "2024-04-18T14:15:56.044842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ],
   "id": "dafa8f761b28bc2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:18:37.608294Z",
     "start_time": "2024-04-18T14:18:37.520664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = pg.Completion.create(\n",
    "    model=\"Neural-Chat-7B\",\n",
    "    prompt=prompt.format(query=\"Generate a question to ask about movie related to this tag: \" + \"spoof\"),\n",
    "    max_tokens=200,\n",
    "    temperature=0.1\n",
    ")\n",
    "try:\n",
    "    questions = Prompt.parse_raw(result['choices'][0]['text'])\n",
    "    print(f\"Prompt: {questions.prompt}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing joke: {e}\")"
   ],
   "id": "aab8741e326405b7",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No access token provided and no predictionguard config file found. Please provide the access token as arguments or set the environment variable PREDICTIONGUARD_TOKEN.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mpg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mNeural-Chat-7B\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGenerate a question to ask about movie related to this tag: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mspoof\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\n\u001B[1;32m      6\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      8\u001B[0m     questions \u001B[38;5;241m=\u001B[39m Prompt\u001B[38;5;241m.\u001B[39mparse_raw(result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/ir/lib/python3.10/site-packages/predictionguard/client.py:132\u001B[0m, in \u001B[0;36mCompletion.create\u001B[0;34m(self, model, prompt, input, output, max_tokens, temperature, top_p)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;124;03mCreates a completion request for the Prediction Guard /completions API.\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m:return: A dictionary containing the completion response.\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;66;03m# Make sure we can connect to prediction guard.\u001B[39;00m\n\u001B[0;32m--> 132\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;66;03m# Create a list of tuples, each containing all the parameters for \u001B[39;00m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;66;03m# a call to _generate_completion\u001B[39;00m\n\u001B[1;32m    136\u001B[0m args \u001B[38;5;241m=\u001B[39m (model, prompt, \u001B[38;5;28minput\u001B[39m, output, max_tokens, temperature, top_p)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/ir/lib/python3.10/site-packages/predictionguard/client.py:109\u001B[0m, in \u001B[0;36mCompletion._connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_connect\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    105\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m    Initialize a Prediction Guard client to check access.\u001B[39;00m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 109\u001B[0m     client \u001B[38;5;241m=\u001B[39m \u001B[43mClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoken \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_token()\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/ir/lib/python3.10/site-packages/predictionguard/client.py:48\u001B[0m, in \u001B[0;36mClient.__init__\u001B[0;34m(self, token)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# If the config file does not exist, raise an error.\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(config_path):\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     49\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo access token provided and no predictionguard\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m config file found. Please provide the access token as \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     51\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marguments or set the environment variable PREDICTIONGUARD_TOKEN.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     52\u001B[0m     )\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;66;03m# Read the JSON config file.\u001B[39;00m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(config_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m config_file:\n",
      "\u001B[0;31mValueError\u001B[0m: No access token provided and no predictionguard config file found. Please provide the access token as arguments or set the environment variable PREDICTIONGUARD_TOKEN."
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f676df5252ec59b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
